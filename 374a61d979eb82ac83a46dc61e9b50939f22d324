{
  "comments": [
    {
      "key": {
        "uuid": "f0820c18_90003c9f",
        "filename": "libc/bionic/pthread_mutex.cpp",
        "patchSetId": 1
      },
      "lineNbr": 343,
      "author": {
        "id": 1042828
      },
      "writtenOn": "2014-10-09T01:50:16Z",
      "side": 1,
      "message": "I don\u0027t see how this can legitimately make a difference, unless there are interesting hardware coherence issues.  There is already a fence to ensure that the contents of the critical section can\u0027t move out of the CS.  The only interesting shared memory accesses getting ordered by the added fence seem to be to mutex-\u003evalue, and those are all to exactly the same location, and hence should not require fencing.\n\nHaving said that, I\u0027m very mildly worried about the algorithm used here.  The comments are a reasonable argument, but I didn\u0027t find them 100% convincing.  A more precise proof seems surprisingly difficult to come by.  I suspect it would be simpler if we had lock and unlock each basically perform load; CAS combination rather than going through multiple atomic steps.\n\nNonetheless, here\u0027s my attempt to show that this doesn\u0027t lose a wakeups:\n\nObservations:\n\nWhenever the state first enters 2, we know that either the futex_wait won\u0027t wait or some thread will eventually be woken.\nEither the thread currently holding the lock will do so, or if\nthe lock was not held, we will.\n\nWhenever the state decreases from 2, wake() is eventually called.\n\nAssume a thread blocks forever in the futex_wait without\nbeing woken.  Consider the last atomic decrement that resulted in a wake call, say by thread 1.  At the wake call we were in one of the following cases:\n\nThere were no waiters.  Means the state never became contended after that \u003d\u003d\u003e impossible; there can\u0027t be any waiters.\n\nstate was unlocked when woken thread called swap\u003d\u003d\u003e woken thread would have made progress, set the state to contended and wake() would have been called again.\n\nstate was locked \u003d\u003d\u003e thread setting state to locked would have made progress, since woken thread would reset state to contended.\n\nstate contended \u003d\u003d\u003e Thread 1 set the state to unlocked.  Since then, some thread 2 set state to locked, some thread 3 is the first to set it to contended after observing the locked state.  If thread 2 completes the unlock decrement before the state is set to contended, thread 3 will make another later decrement wake call, since it sees an unlocked mutex value but nontheless sets the state to contended.  Otherwise thread 2 will do so after seeing the contended state.\n\nIn all cases we get a contradiction.\n\nThus, in spite of my negative comments, I actually kind of believe the algorithm as is.",
      "range": {
        "startLine": 343,
        "startChar": 9,
        "endLine": 343,
        "endChar": 31
      },
      "revId": "374a61d979eb82ac83a46dc61e9b50939f22d324",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "50c2f81e_c51475b4",
        "filename": "libc/bionic/pthread_mutex.cpp",
        "patchSetId": 1
      },
      "lineNbr": 343,
      "author": {
        "id": 1037505
      },
      "writtenOn": "2014-10-09T17:05:49Z",
      "side": 1,
      "message": "Thanks Hans. I agree with you. I find it weird that a barrier could do any difference at that position, when the compare-exchange is guaranteed to have failed. After all, if the cmpxchg fails, then this means that the current thread hasn\u0027t written anything to memory. Why would it need a barrier, then?\n\nOrjan Eide, who has carried out most of the investigations on the issue so far, has just confirmed that the barrier above does only reduce the rate at which the bug occurs. In other words, the fix in this CL is know not to work. He has moved the barrier below (see comment) and this - so far - seems to have removed the issue (or has lowered the occurrence rate enough to require longer observation times). I hope I will have more time to look into this tomorrow (so far I have been hugely distracted by other issues and couldn\u0027t even attempt to reproduce the bug myself).",
      "parentUuid": "f0820c18_90003c9f",
      "revId": "374a61d979eb82ac83a46dc61e9b50939f22d324",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "d087c827_afa95d9f",
        "filename": "libc/bionic/pthread_mutex.cpp",
        "patchSetId": 1
      },
      "lineNbr": 379,
      "author": {
        "id": 1037505
      },
      "writtenOn": "2014-10-09T17:05:49Z",
      "side": 1,
      "message": "A barrier here seems to work better.",
      "revId": "374a61d979eb82ac83a46dc61e9b50939f22d324",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "508af82f_53dfbc1b",
        "filename": "libc/bionic/pthread_mutex.cpp",
        "patchSetId": 1
      },
      "lineNbr": 379,
      "author": {
        "id": 1042828
      },
      "writtenOn": "2014-10-09T18:40:35Z",
      "side": 1,
      "message": "The failure is a deadlock on ARMv8?\n\nThis at least weakly suggests that the __futex_wake_ex call may not ensure ordering we expect, and the assignment to value is not yet visible when the other thread wakes up.  That would also break other code in Android.\n\nBased on a quick examination of the kernel code, it is conceivable to me that there may be a problem here that was introduced with ARMv8.  Futex_wake acquires a spin lock and then calls wake_futex.  The spin lock presumably used to include a dmb which would have somewhat accidentally prevented this.  That\u0027s presumably now an exclusive acquire load, which would not.  I would be mildly surprised if there is not another dmb on kernel entry to prevent this.  If this is indeed the problem, it should also break on Itanium, though possibly not on real hardware.\n\nIf this is the problem, I think the correct place to fix it is in the kernel.  The fence here may be an actual workaround, but we would need several more like it.",
      "parentUuid": "d087c827_afa95d9f",
      "revId": "374a61d979eb82ac83a46dc61e9b50939f22d324",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "b0ba54ec_58b67d60",
        "filename": "libc/bionic/pthread_mutex.cpp",
        "patchSetId": 1
      },
      "lineNbr": 379,
      "author": {
        "id": 1037505
      },
      "writtenOn": "2014-10-10T17:31:52Z",
      "side": 1,
      "message": "If I read the bug report correctly the issue has been observed when running both 32-bit and 64-bit versions of the same application on 64-bit Android (this should be confirmed shortly) on an ARMv8 system. It seems to only occurs when running threads across different CPU clusters. One thread hangs forever in __futex_wake_ex(). Orjan\u0027s gdb investigations suggest that the thread should have been waked up, but it hasn\u0027t. Note that the issue hasn\u0027t yet been observed when forcing the threads to run on the same cluster ([all on A53 cores] or [all on A57 cores]). While I didn\u0027t have a lot of time today to work on this, I had enough to prepare a filesystem and reproduce the issue. Hopefully, next week I\u0027ll gather more info.",
      "parentUuid": "508af82f_53dfbc1b",
      "revId": "374a61d979eb82ac83a46dc61e9b50939f22d324",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "10f960d6_e61c8092",
        "filename": "libc/bionic/pthread_mutex.cpp",
        "patchSetId": 1
      },
      "lineNbr": 379,
      "author": {
        "id": 1042828
      },
      "writtenOn": "2014-10-10T18:07:33Z",
      "side": 1,
      "message": "That still seems consistent with my conjecture that it\u0027s the lack of a fence in the kernel.  The deciding factor would be whether the kernel spin-lock implementation uses an acquire load or a dmb, which would presumably depend only on whether the kernel is 64-bit.  This would be highly dependent on weird timing, so it wouldn\u0027t surprise me if it occurred only in certain CPU configurations.  But the more I think about, the more I remain highly suspicious of my conjecture that there is no other kernel synchronization that would force sufficient memory ordering.\n\nDo you have a kernel expert involved or should I see if I can find one here?",
      "parentUuid": "b0ba54ec_58b67d60",
      "revId": "374a61d979eb82ac83a46dc61e9b50939f22d324",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    }
  ]
}