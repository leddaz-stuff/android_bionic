From ffe4efa9388be33f9eeb85b85696180c5be62d75 Mon Sep 17 00:00:00 2001
From: Kalesh Singh <kaleshsingh@google.com>
Date: Thu, 18 Jul 2024 14:23:31 -0700
Subject: [PATCH 02/20] Introduce LoadSegments4kBCompat

Change-Id: Ic8f0ddcf3dce034b854480b557035692faad3af1
---
 linker/linker_phdr.cpp        |   9 +--
 linker/linker_phdr.h          |   6 ++
 linker/linker_phdr_compat.cpp | 144 ++++++++++++++++++++++++++++++++++
 3 files changed, 154 insertions(+), 5 deletions(-)

diff --git a/linker/linker_phdr.cpp b/linker/linker_phdr.cpp
index b5d3fefc5..29f3981dc 100644
--- a/linker/linker_phdr.cpp
+++ b/linker/linker_phdr.cpp
@@ -140,11 +140,6 @@ static int GetTargetElfMachine() {
 
  **/
 
-#define MAYBE_MAP_FLAG(x, from, to)  (((x) & (from)) ? (to) : 0)
-#define PFLAGS_TO_PROT(x)            (MAYBE_MAP_FLAG((x), PF_X, PROT_EXEC) | \
-                                      MAYBE_MAP_FLAG((x), PF_R, PROT_READ) | \
-                                      MAYBE_MAP_FLAG((x), PF_W, PROT_WRITE))
-
 static const size_t kPageSize = page_size();
 
 /*
@@ -837,6 +832,10 @@ static inline void _extend_load_segment_vma(const ElfW(Phdr)* phdr_table, size_t
 }
 
 bool ElfReader::LoadSegments() {
+  if (min_load_alignment(phdr_table_, phdr_num_) < kPageSize && loader_4kb_compat_enabled()) {
+    return LoadSegments4kbCompat();
+  }
+
   for (size_t i = 0; i < phdr_num_; ++i) {
     const ElfW(Phdr)* phdr = &phdr_table_[i];
 
diff --git a/linker/linker_phdr.h b/linker/linker_phdr.h
index aab9018b4..c6e5cfce0 100644
--- a/linker/linker_phdr.h
+++ b/linker/linker_phdr.h
@@ -39,6 +39,11 @@
 #include "linker_mapped_file_fragment.h"
 #include "linker_note_gnu_property.h"
 
+#define MAYBE_MAP_FLAG(x, from, to)  (((x) & (from)) ? (to) : 0)
+#define PFLAGS_TO_PROT(x)            (MAYBE_MAP_FLAG((x), PF_X, PROT_EXEC) | \
+                                      MAYBE_MAP_FLAG((x), PF_R, PROT_READ) | \
+                                      MAYBE_MAP_FLAG((x), PF_W, PROT_WRITE))
+
 class ElfReader {
  public:
   ElfReader();
@@ -69,6 +74,7 @@ class ElfReader {
   [[nodiscard]] bool ReadPadSegmentNote();
   [[nodiscard]] bool ReserveAddressSpace(address_space_params* address_space);
   [[nodiscard]] bool LoadSegments();
+  [[nodiscard]] bool LoadSegments4kbCompat();
   [[nodiscard]] bool FindPhdr();
   [[nodiscard]] bool FindGnuPropertySection();
   [[nodiscard]] bool CheckPhdr(ElfW(Addr));
diff --git a/linker/linker_phdr_compat.cpp b/linker/linker_phdr_compat.cpp
index d82a45c89..1e954974e 100644
--- a/linker/linker_phdr_compat.cpp
+++ b/linker/linker_phdr_compat.cpp
@@ -27,6 +27,18 @@
  */
 
 #include "linker_phdr_compat.h"
+#include "linker_phdr.h"
+
+#include "linker_dlwarning.h"
+#include "linker_globals.h"
+#include "linker_debug.h"
+
+#include "platform/bionic/page.h"
+
+#include <linux/prctl.h>  /* Definition of PR_* constants */
+#include <sys/prctl.h>
+
+static const size_t kPageSize = page_size();
 
 bool loader_4kb_compat_enabled() {
   return true;
@@ -53,3 +65,135 @@ ElfW(Addr) min_load_alignment(const ElfW(Phdr)* phdr_table, size_t phdr_count) {
 
   return min_align;
 }
+
+bool ElfReader::LoadSegments4kbCompat() {
+  for (size_t i = 0; i < phdr_num_; ++i) {
+    const ElfW(Phdr)* phdr = &phdr_table_[i];
+
+    if (phdr->p_type != PT_LOAD) {
+      continue;
+    }
+
+    ElfW(Addr) p_memsz = phdr->p_memsz;
+    ElfW(Addr) p_filesz = phdr->p_filesz;
+
+    // Segment addresses in memory.
+    ElfW(Addr) seg_start = phdr->p_vaddr + load_bias_;
+    ElfW(Addr) seg_end = seg_start + p_memsz;
+
+    ElfW(Addr) seg_page_start = page_start(seg_start);
+    ElfW(Addr) seg_page_end = page_end(seg_end);
+
+    ElfW(Addr) seg_file_end = seg_start + p_filesz;
+
+    // File offsets.
+    ElfW(Addr) file_start = phdr->p_offset;
+    ElfW(Addr) file_end = file_start + p_filesz;
+
+    ElfW(Addr) file_page_start = page_start(file_start);
+    ElfW(Addr) file_length = file_end - file_page_start;
+
+    if (file_size_ <= 0) {
+      DL_ERR("\"%s\" invalid file size: %" PRId64, name_.c_str(), file_size_);
+      return false;
+    }
+
+    if (file_start + phdr->p_filesz > static_cast<size_t>(file_size_)) {
+      DL_ERR("invalid ELF file \"%s\" load segment[%zd]:"
+          " p_offset (%p) + p_filesz (%p) ( = %p) past end of file (0x%" PRIx64 ")",
+          name_.c_str(), i, reinterpret_cast<void*>(phdr->p_offset),
+          reinterpret_cast<void*>(phdr->p_filesz),
+          reinterpret_cast<void*>(file_start + phdr->p_filesz), file_size_);
+      return false;
+    }
+
+    if (file_length != 0) {
+      int prot = PFLAGS_TO_PROT(phdr->p_flags);
+      if ((prot & (PROT_EXEC | PROT_WRITE)) == (PROT_EXEC | PROT_WRITE)) {
+        // W + E PT_LOAD segments are not allowed in O.
+        if (get_application_target_sdk_version() >= 26) {
+          DL_ERR_AND_LOG("\"%s\": W+E load segments are not allowed", name_.c_str());
+          return false;
+        }
+        DL_WARN_documented_change(26,
+                                  "writable-and-executable-segments-enforced-for-api-level-26",
+                                  "\"%s\" has load segments that are both writable and executable",
+                                  name_.c_str());
+        add_dlwarning(name_.c_str(), "W+E load segments");
+      }
+
+      if (phdr->p_align < kPageSize && loader_4kb_compat_enabled()) {
+        lseek(fd_, file_offset_ + file_page_start, SEEK_SET);
+        read(fd_, reinterpret_cast<void*>(seg_page_start), file_length);
+      } else {
+        void* seg_addr = mmap64(reinterpret_cast<void*>(seg_page_start),
+                              file_length,
+                              prot,
+                              MAP_FIXED|MAP_PRIVATE,
+                              fd_,
+                              file_offset_ + file_page_start);
+        if (seg_addr == MAP_FAILED) {
+          DL_ERR("couldn't map \"%s\" segment %zd: %s", name_.c_str(), i, strerror(errno));
+          return false;
+        }
+      }
+    }
+
+    // if the segment is writable, and does not end on a page boundary,
+    // zero-fill it until the page limit.
+    //
+    // Do not attempt to zero the extended region past the first partial page,
+    // since doing so may:
+    //   1) Result in a SIGBUS, as the region is not backed by the underlying
+    //      file.
+    //   2) Break the COW backing, faulting in new anon pages for a region
+    //      that will not be used.
+
+    uint64_t unextended_seg_file_end = seg_start + phdr->p_filesz;
+    if ((phdr->p_flags & PF_W) != 0 && page_offset(unextended_seg_file_end) > 0) {
+      memset(reinterpret_cast<void*>(unextended_seg_file_end), 0,
+             kPageSize - page_offset(unextended_seg_file_end));
+    }
+
+    // Pages may be brought in due to readahead.
+    // Drop the padding (zero) pages, to avoid reclaim work later.
+    //
+    // NOTE: The madvise() here is special, as it also serves to hint to the
+    // kernel the portion of the LOAD segment that is padding.
+    //
+    // See: [1] https://android-review.googlesource.com/c/kernel/common/+/3032411
+    //      [2] https://android-review.googlesource.com/c/kernel/common/+/3048835
+    uint64_t pad_start = page_end(unextended_seg_file_end);
+    uint64_t pad_end = page_end(seg_file_end);
+    CHECK(pad_start <= pad_end);
+    uint64_t pad_len = pad_end - pad_start;
+    if (page_size_migration_supported() && pad_len > 0 &&
+        madvise(reinterpret_cast<void*>(pad_start), pad_len, MADV_DONTNEED)) {
+      DL_WARN("\"%s\": madvise(0x%" PRIx64 ", 0x%" PRIx64 ", MADV_DONTNEED) failed: %m",
+              name_.c_str(), pad_start, pad_len);
+    }
+
+    seg_file_end = page_end(seg_file_end);
+
+    // seg_file_end is now the first page address after the file
+    // content. If seg_end is larger, we need to zero anything
+    // between them. This is done by using a private anonymous
+    // map for all extra pages.
+    if (seg_page_end > seg_file_end) {
+      size_t zeromap_size = seg_page_end - seg_file_end;
+      void* zeromap = mmap(reinterpret_cast<void*>(seg_file_end),
+                           zeromap_size,
+                           PFLAGS_TO_PROT(phdr->p_flags),
+                           MAP_FIXED|MAP_ANONYMOUS|MAP_PRIVATE,
+                           -1,
+                           0);
+      if (zeromap == MAP_FAILED) {
+        DL_ERR("couldn't zero fill \"%s\" gap: %s", name_.c_str(), strerror(errno));
+        return false;
+      }
+
+      prctl(PR_SET_VMA, PR_SET_VMA_ANON_NAME, zeromap, zeromap_size, ".bss");
+    }
+  }
+  return true;
+}
-- 
2.45.2.1089.g2a221341d9-goog

